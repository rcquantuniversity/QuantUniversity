#
# We are using a GCE disk as persistent storage for the Hub
# and for each individual user node.
#
# A volume for the hub is automatically provisioned b/c its pvc
# is using a storage class. There is no need to manually provision
# any disks on the cluster.
#
# When a single user pod is spun up, a corresponding pvc is
# dynamically provisioned by kubespawner. If a pvc for that user
# already exists, the pod mounts to the existing pvc.
#
apiVersion: v1
kind: Service
metadata:
  name: proxy-api
  {{ if .Values.name }}namespace: {{ .Values.name }} {{ end }}
spec:
  selector:
    name: proxy-pod
  ports:
    - protocol: TCP
      port: 8001
      targetPort: 8001
---
apiVersion: v1
kind: Service
metadata:
  name: proxy-public
  {{ if .Values.name }}namespace: {{ .Values.name }} {{ end }}
spec:
  type: LoadBalancer
  {{ if .Values.publicIP }}
  loadBalancerIP: {{ .Values.publicIP }}
  {{ end }}
  selector:
    name: proxy-pod
  ports:
    - protocol: TCP
      port: 80
      targetPort: 8000
---
apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: proxy-deployment
  {{ if .Values.name }}namespace: {{ .Values.name }} {{ end }}
spec:
  replicas: 1
  template:
    metadata:
      labels:
        name: proxy-pod
        {{ if .Values.proxy.labels -}}
        # Because toYaml + indent is super flaky
        {{ range $key, $value := .Values.proxy.labels -}}
        {{ $key }}: {{ $value | quote }}
        {{- end }}
        {{- end }}
    spec:
      containers:
      - name: proxy-container
        image: {{ .Values.proxy.image.name }}:{{ .Values.proxy.image.tag }}
        resources:
{{ toYaml .Values.proxy.resources | indent 12 }}
        env:
          - name: CONFIGPROXY_AUTH_TOKEN
            valueFrom:
              secretKeyRef:
                name: hub-secret
                key: proxy.token
        ports:
          - containerPort: 8000
            name: proxy-public
          - containerPort: 8001
            name: api
